{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering process\n",
    "\n",
    "Three dataframes with info on tweets of the WeRateDogs twitter account were generated using three different methods: <br>\n",
    "\n",
    "\n",
    "1. df_tweet: containing basic tweet info, inluding tweet text, dog rating, dog name and dog stage <br>\n",
    "    _Method: Direct download of a .csv file (twitter_archive_enhanced.csv)_ <br>\n",
    "   \n",
    "    \n",
    "2. df_image: containing image url and predicted dog breed based on the image <br>\n",
    "   _Methods: Download of a .tsv file using the Request library (image_predictions.tsv)_ <br>\n",
    "      \n",
    "      \n",
    "3. df_count: containing like count, reply count, retweet count and quote count <br>\n",
    "    _Method: Query of additional tweet data via the Twitter API using Tweepy library_\n",
    "\n",
    "Sources used for the gathering data via the Twitter API:    \n",
    "\n",
    "https://docs.tweepy.org/en/v4.0.1/client.html \n",
    "\n",
    "https://stackoverflow.com/questions/70371657/problem-with-getting-tweet-fields-from-twitter-api-2-0-using-tweepy\n",
    "\n",
    "https://dev.to/twitterdev/a-comprehensive-guide-for-using-the-twitter-api-v2-using-tweepy-in-python-15d9\n",
    "\n",
    "https://stackoverflow.com/questions/3494906/how-do-i-merge-a-list-of-dicts-into-a-single-dict\n",
    "\n",
    "https://stackoverflow.com/questions/59687201/how-to-convert-a-txt-file-with-dictionary-format-to-dataframe-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing process\n",
    "\n",
    "For this project only original tweets including an image and dog rating were of interest. In addition, the dataset contains more issues than addressed here, but the main once necessary for analysis were assessed and cleaned. An overview of the quality and tidiness issues is listed below. \n",
    "\n",
    "#### Quality issues\n",
    "##### `tweet` table\n",
    "- Non-original ratings (retweets and replies)\n",
    "- Erroneous datatypes:\n",
    "    * timestamp from object to datetime\n",
    "- Incorrect names in column 'name' of df_tweet:\n",
    "    * 745 rows with 'None' --> NaN\n",
    "    * 109 rows with incorrectly identified names as 'the', 'a', 'an', 'such', 'quite' and more. \n",
    "    * \"O\" instead of \"O'Malley\" \n",
    "- Incorrect ratings \n",
    "    - Incorrectly detected ratings (e.g. values as 24/7, 7/11 and 50/50 that have been mistaken for a rating value)\n",
    "    - Incorrectly detected numerator values (e.g. 9.75 is read as 75)\n",
    "    - Ratings with a denominator above 10\n",
    "- Multiple dog breed predictions per image. The neural network used for gathering dog breed predictions based on an image does three attempts in detecting the dog breed. In some cases this results in the detection of multiple dog breeds per image. For analysis, only one is needed. \n",
    "    - Images with >1 true dog breed prediction\n",
    "- Tweet text column has two variable: tweet text and url. \n",
    "- Rows with duplicated and non-twitter urls in expanded_urls column\n",
    "\n",
    "##### `image` table\n",
    "\n",
    "- No detected dog breed for some images\n",
    "    - 'False' image prediction for the first, second and third prediction. \n",
    "    \n",
    "- Non-dog images \n",
    "    - Non-dog images with a false 'dog breed' prediction in the first and second attempt, but a true 'dog breed' prediction in the final attempt. These include tweet id's: **668297328638447616, 673345638550134785, 679854723806179328, 671163268581498880, 667524857454854144, 671141549288370177, 678740035362037760, 670452855871037440**\n",
    "\n",
    "- Missing image predictions for some tweets (Image table has less data than the tweet table)\n",
    "\n",
    "- Inconsistent use of capital letters in column p1, p2 and p3 \n",
    "\n",
    "### Tidiness issues\n",
    "- The variable 'dog stage' in the `tweet` table is spread over four columns instead of one (Note: tweets containing 2 different dog stages in their text will appear as two values in one cell)\n",
    "\n",
    "- `Image` table: Four variables in nine columns (p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog). The four variables: prediction number (1,2 or 3), predicted breed (name), confidence (%), dog breed (yes/no) \n",
    "\n",
    "- Too many tables. The `tweet`, `image` and `count` table can be merged into a tweet and content specifications table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning process\n",
    "\n",
    "All the issues listed above were succesfully handled in the cleaning process, following the same order. Except, merging of the dataframes (final point on the list) was done earlier in the cleaning process to delete tweets of which no image was available. <br>\n",
    "\n",
    "Regarding the image table issues: although cleaned thoroughly, it cannot be excluded that there are still some non-dog images in the dataset, neither that some true dog images were deleted: <br>\n",
    "\n",
    "- All images for which no dog breed was detected (three false detections) were deleted. However, this does not necessarily mean all of them concerned non-dog images. For low quality images the dog breed detection system may have failed in all three attempts. <br> \n",
    "\n",
    "- I manually assessed the images that had 2 false dog breed predections during the first 2 attempt and excluded those without a dog image from the dataset. That means that in some cases the third prediction was wrongly labeled as a true dog breed. Since not all images have been manually assessed the presence of non-dog images in the final dataset cannot be excluded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!jupyter nbconvert --to html --no-input --no-prompt wrangle_report.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
